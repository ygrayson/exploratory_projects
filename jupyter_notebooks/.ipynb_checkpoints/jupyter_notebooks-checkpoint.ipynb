{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Jupyter Notebook for EECS 445 - Intro to Machine Learning, Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-2-1fd5fbe607ba>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-1fd5fbe607ba>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    path = \"C:\\\\Users\\\\apple\\\\Downloads\\\"\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "EECS 445 - Introduction to Machine Learning\n",
    "Fall 2019 - Project 2\n",
    "Posters Dataset\n",
    "    Class wrapper for interfacing with the dataset of movie poster images\n",
    "\"\"\"\n",
    "\n",
    "path = \"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from imageio import imread\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_test_loaders(num_classes):\n",
    "    tr, va, te, _ = get_train_val_dataset(num_classes=num_classes)\n",
    "\n",
    "    batch_size = config('cnn.batch_size')\n",
    "    tr_loader = DataLoader(tr, batch_size=batch_size, shuffle=True)\n",
    "    va_loader = DataLoader(va, batch_size=batch_size, shuffle=False)\n",
    "    te_loader = DataLoader(te, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return tr_loader, va_loader, te_loader, tr.get_semantic_label\n",
    "\n",
    "def get_train_val_dataset(num_classes=10):\n",
    "    tr = PostersDataset('train', num_classes) #training set\n",
    "    va = PostersDataset('val', num_classes) #validation set\n",
    "    te = PostersDataset('test', num_classes) #testing set\n",
    "\n",
    "    #DEBUG\n",
    "    #print(len(tr))\n",
    "\n",
    "    # Resize\n",
    "    tr.X = resize(tr.X)\n",
    "    va.X = resize(va.X)\n",
    "    te.X = resize(te.X)\n",
    "\n",
    "    # Standardize\n",
    "    standardizer = ImageStandardizer()\n",
    "    standardizer.fit(tr.X)\n",
    "    tr.X = standardizer.transform(tr.X)\n",
    "    va.X = standardizer.transform(va.X)\n",
    "    te.X = standardizer.transform(te.X)\n",
    "\n",
    "    # Transpose the dimensions from (N,H,W,C) to (N,C,H,W)\n",
    "    tr.X = tr.X.transpose(0,3,1,2)\n",
    "    va.X = va.X.transpose(0,3,1,2)\n",
    "    te.X = te.X.transpose(0,3,1,2)\n",
    "\n",
    "    return tr, va, te, standardizer\n",
    "\n",
    "def resize(X):\n",
    "    \"\"\"\n",
    "    Resizes the data partition X to the size specified in the config file.\n",
    "    Uses bicubic interpolation for resizing.\n",
    "    X - multi-dimensional numpy array, each X[i] is the ith poster input\n",
    "\n",
    "    Returns:\n",
    "        the resized images as a numpy array.\n",
    "    \"\"\"\n",
    "    # DONE: Complete this function\n",
    "    image_dim = config('image_dim')\n",
    "\n",
    "    resized = []\n",
    "    for img in X:\n",
    "        pillow_im = Image.fromarray(img)\n",
    "        pillow_im.resize((image_dim, image_dim), resample=Image.BICUBIC)\n",
    "        # augment into the new numpy array\n",
    "        resized.append(np.array(pillow_im))\n",
    "\n",
    "    return resized\n",
    "\n",
    "class ImageStandardizer(object):\n",
    "    \"\"\"\n",
    "    Channel-wise standardization for batch of images to mean 0 and variance 1.\n",
    "    The mean and standard deviation parameters are computed in `fit(X)` and\n",
    "    applied using `transform(X)`.\n",
    "\n",
    "    X has shape (N, image_height, image_width, color_channel)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image_mean = None\n",
    "        self.image_std = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # DONE: Complete this function\n",
    "        self.image_std = [] #list of tuples that contains all the variance of each EGB values\n",
    "\n",
    "        # find RGB mean of all poster image\n",
    "        total_RGB = [0, 0, 0] \n",
    "        total_entry = 0\n",
    "        \n",
    "        for poster_img in X:\n",
    "            length = len(poster_img)\n",
    "            width = len(poster_img[0])\n",
    "            img_total = poster_img.sum(axis=(0,1))\n",
    "            total_RGB += img_total\n",
    "            total_entry += length*width\n",
    "            \n",
    "        #self.image_mean is [average_R, average_G, average_B] for all training dataset\n",
    "        self.image_mean = total_RGB / total_entry\n",
    "\n",
    "        # find RGB variance for all poster image\n",
    "        total_square = [0, 0, 0]\n",
    "        for poster_img in X:\n",
    "            length = len(poster_img)\n",
    "            width = len(poster_img[0])\n",
    "            for i in range(length):\n",
    "                for j in range(width):\n",
    "                    total_square[0] += (poster_img[i][j][0] - self.image_mean[0]) ** 2\n",
    "                    total_square[1] += (poster_img[i][j][1] - self.image_mean[1]) ** 2\n",
    "                    total_square[2] += (poster_img[i][j][2] - self.image_mean[2]) ** 2\n",
    "        \n",
    "        #self.image_std is [std_R, std_G, std_B] for all training dataset\n",
    "        self.image_std = (total_square / total_entry) ** 0.5\n",
    "\n",
    "    def transform(self, X):\n",
    "        # DONE: Complete this function\n",
    "        for idx in range(len(X)):\n",
    "            for i in range(len(X[0])):\n",
    "                for j in range(len(X[0][0])):\n",
    "                    for k in range(3):\n",
    "                        # normalize each channel (RGB) with regarding to its mean and std\n",
    "                        X[idx][i][j][k] = (X[idx][i][j][k] - self.image_mean[k]) / self.image_std[k]\n",
    "\n",
    "\n",
    "\n",
    "class PostersDataset(Dataset):\n",
    "\n",
    "    def __init__(self, partition, num_classes=10):\n",
    "        \"\"\"\n",
    "        Reads in the necessary data from disk.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if partition not in ['train', 'val', 'test']:\n",
    "            raise ValueError('Partition {} does not exist'.format(partition))\n",
    "\n",
    "        np.random.seed(0)\n",
    "        self.partition = partition\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Load in all the data we need from disk\n",
    "        self.metadata = pd.read_csv(config('csv_file'))\n",
    "        self.X, self.y = self._load_data()\n",
    "\n",
    "        self.semantic_labels = dict(zip(\n",
    "            self.metadata['numeric_label'],\n",
    "            self.metadata['semantic_label']\n",
    "        ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx]).float(), torch.tensor(self.y[idx]).long()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"\n",
    "        Loads a single data partition from file.\n",
    "        \"\"\"\n",
    "        print(\"loading %s...\" % self.partition)\n",
    "\n",
    "        if self.partition == 'test':\n",
    "            if self.num_classes == 5:\n",
    "                df = self.metadata[self.metadata.partition == self.partition]\n",
    "            elif self.num_classes == 10:\n",
    "                df = self.metadata[self.metadata.partition.isin([self.partition, ' '])]\n",
    "            else:\n",
    "                raise ValueError('Unsupported test partition: num_classes must be 5 or 10')\n",
    "        else:\n",
    "            df = self.metadata[\n",
    "                (self.metadata.numeric_label < self.num_classes) &\n",
    "                (self.metadata.partition == self.partition)\n",
    "            ]\n",
    "\n",
    "        X, y = [], []\n",
    "        for i, row in df.iterrows():\n",
    "            label = row['numeric_label']\n",
    "            image = imread(os.path.join(config('image_path'), row['filename']), pilmode='RGB')\n",
    "            X.append(image)\n",
    "            y.append(row['numeric_label'])\n",
    "\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def get_semantic_label(self, numeric_label):\n",
    "        \"\"\"\n",
    "        Returns the string representation of the numeric class label (e.g.,\n",
    "        the numberic label 1 maps to the semantic label 'miniature_poodle').\n",
    "        \"\"\"\n",
    "        return self.semantic_labels[numeric_label]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ## Future note: check scipy imread and imresize\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "    np.set_printoptions(precision=3)\n",
    "\n",
    "    # load training, validation and testing dataset\n",
    "    tr, va, te, standardizer = get_train_val_dataset()\n",
    "    print(\"Train:\\t\", len(tr.X))\n",
    "    print(\"Val:\\t\", len(va.X))\n",
    "    print(\"Test:\\t\", len(te.X))\n",
    "    print(\"Mean:\", standardizer.image_mean)\n",
    "    print(\"Std: \", standardizer.image_std)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
